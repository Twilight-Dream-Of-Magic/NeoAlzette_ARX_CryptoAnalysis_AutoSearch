Linear Approximations of Addition Modulo 2n
Johan WalleÌn
Laboratory for Theoretical Computer Science
Helsinki University of Technology
P.O.Box 5400, FIN-02015 HUT, Espoo, Finland
johan@tcs.hut.fi

Abstract. We present an in-depth algorithmic study of the linear approximations of addition modulo 2n . Our results are based on a fairly
simple classiï¬cation of the linear approximations of the carry function.
Using this classiï¬cation, we derive an Î˜(log n)-time algorithm for computing the correlation of linear approximation of addition modulo 2n , an
optimal algorithm for generating all linear approximations with a given
non-zero correlation coeï¬ƒcient, and determine the distribution of the
correlation coeï¬ƒcients. In the generation algorithms, one or two of the
selection vectors can optionally be ï¬xed. The algorithms are practical
and easy to implement.
Keywords: Linear approximations, correlation, modular addition, linear
cryptanalysis.

1

Introduction

Linear cryptanalysis [8] is one of the most powerful general cryptanalytic methods for block ciphers proposed by date. Since its introduction, resistance against
this attack has been a standard design goal for block ciphers. Although some
design methodologies to achieve this goal have been proposedâ€”for example [12,
10, 4, 13]â€”many block ciphers are still designed in a rather ad hoc manner, or
dictated by other primary design goals. For these ciphers, it it important to have
eï¬ƒcient methods for evaluating their resistance against linear cryptanalysis.
At the heart of linear cryptanalysis lies the study of the correlation of linear
approximate relations between the input and output of functions. Good linear
approximations of ciphers are usually found heuristically by forming trails consisting of linear approximations of the components of the cipher. In order to
search the space of linear trails, e.g. using a Branch-and-bound algorithm (see
e.g. [5, 9, 1]), we need eï¬ƒcient methods for computing the correlation of linear
approximations of the simplest components of the cipher, as well as methods for
generating the relevant approximations of the components. Towards this goal,
we study a few basic functions often used in block ciphers.
Currently, block ciphers are usually build from local nonlinear mappings,
global linear mappings, and arithmetic operations. The mixture of linear mappings and arithmetic operations seems fruitful, since they are suitable for software implementation, and their mixture is diï¬ƒcult to analyse mathematically.
T. Johansson (Ed.): FSE 2003, LNCS 2887, pp. 261â€“273, 2003.
c International Association for Cryptologic Research 2003


262

Johan WalleÌn

While the latter property intuitively should make standard cryptanalysis intractable , it also makes it diï¬ƒcult to say something concrete about the security
of the cipher.
Perhaps the simplest arithmetic operations in wide use are addition and subtraction modulo 2n . Interestingly, good tools for studying linear approximations
of even these simple mappings have not appeared in the literature to date. In this
paper, we consider algorithms for two important problems for linear approximations of these operations: for computing the correlation of any given linear approximation and for generating all approximations with a correlation coeï¬ƒcient
of a given absolute value. Our results are based on a fairly simple classiï¬cation
of the linear approximations of the carry function. Using this classiï¬cation, we
derive Î˜(log n)-time algorithms for computing the correlation of of linear approximations of addition and subtraction modulo 2n in a standard RAM model
of computation. The classiï¬cation also gives optimal (that is, linear in the size
of the output) algorithms for generating all linear approximations of addition or
subtraction with a given non-zero correlation. In the generation algorithms, one
or two of the selection vectors may optionally be ï¬xed. As a simple corollary, we
determine closed-form expressions for the distribution of the correlation coeï¬ƒcients. We hope that our result will facilitate advanced linear cryptanalysis of
ciphers using modular arithmetic.
Similar results with respect to diï¬€erential cryptanalysis [2] are discussed in [7,
6]. The simpler case with one addend ï¬xed is considered in [11] with respect to
both linear and diï¬€erential cryptanalysis.
In the next section, we discuss linear approximations and some preliminary
results. In Sect. 3, we derive our classiï¬cation of linear approximations of the
carry function, and the corresponding results for addition and subtraction. Using
this classiï¬cation, we then present the Î˜(log n)-time algorithm for computing
the correlation of linear approximations in Sect. 4, and the generation algorithms
in Sect. 5.

2

Preliminaries

2.1

Linear Approximations

Linear cryptanalysis [8] views (a part of) the cipher as a relation between the
plaintext, the ciphertext and the key, and tries to approximate this relation using
linear relations. The following standard terminology is convenient for discussing
these linear approximations.
Let f, g : IFn2 â†’ IF2 be Boolean functions. The correlation between f and g
is deï¬ned by


c(f, g) = 21âˆ’n {x âˆˆ IFn2 | f (x) = g(x)} âˆ’ 1 .
This is simply the probability taken over x that f (x) = g(x) scaled to a value in
n
t
[âˆ’1, 1]. Let u = (umâˆ’1 , . . . , u0 )t âˆˆ IFm
2 and w = (wnâˆ’1 , . . . , w0 ) âˆˆ IF2 be binary
n
m
column vectors, and let h : IF2 â†’ IF2 . Let w Â· x = wnâˆ’1 xnâˆ’1 + Â· Â· Â· + w1 x1 + w0 x0
denote the standard dot product. Deï¬ne the linear function lw : IFn2 â†’ IF2 by
lw (x) = w Â· x for all w âˆˆ IFn2 . A linear approximation of h is an approximate

Linear Approximations of Addition Modulo 2n

263

relation of the form u Â· h(x) = w Â· x. Such a linear approximation will be denoted
h

âˆ’ w, or simply u â†
âˆ’ w when h is clear from context.
by the formal expression u â†
h
Its eï¬ƒciency is measured by its correlation C(u â†
âˆ’ w) deï¬ned by
h

âˆ’ w) = c(lu â—¦ h, lw ) .
C(u â†
Here, u and w are the output and input selection vectors, respectively.
2.2

Fourier Analysis

There is a well-known Fourier-based framework for studying linear approximations [3]. Let f : IFn2 â†’ IF2 be a Boolean function. The corresponding realvalued function fË†: IFn2 â†’ IR is deï¬ned by fË†(x) = (âˆ’1)f (x) . With this notation,

c(f, g) = 2âˆ’n xâˆˆIFn fË†(x)gÌ‚(x). Note also that f + g â†” fË†gÌ‚. Recall that an al2
gebra A over a ï¬eld IF is a ring, such that A is a vector space over IF, and
a(xy) = (ax)y = x(ay) for all a âˆˆ IF and x, y âˆˆ A.
Deï¬nition 1. Let Bn = fË† | f : IFn2 â†’ IF2  be the real algebra generated by the
n-variable Boolean functions. As usual, the addition, multiplication, and multiplication by scalars are given by (Î¾ + Î·)(x) = Î¾(x) + Î·(x), (Î¾Î·)(x) = Î¾(x)Î·(x)
and (aÎ¾)(x) = a(Î¾(x)) for all Î¾, Î· âˆˆ Bn and a âˆˆ IR.
The algebra Bn is of course unital and commutative.
The vector space Bn is turned into an inner product space by adopting the
standard inner product for real-valued discrete functions. This inner product is
deï¬ned by

Î¾, Î· = 2âˆ’n
(Î¾Î·)(x) , âˆ€Î¾, Î· âˆˆ Bn .
xâˆˆIFn
2

For Boolean functions, f, g : IFn2 â†’ IF2 , fË†, gÌ‚ = c(f, g). Since the set of linear
functions {Ë†lw | w âˆˆ IFn2 } forms an orthonormal basis for Bn , every Î¾ âˆˆ Bn has a
unique representation as

Î±w Ë†lw , where Î±w = Î¾, Ë†lw  âˆˆ IR .
Î¾=
wâˆˆIFn
2

The corresponding Fourier transform F : Bn â†’ Bn is given by
F(Î¾) = Î , where Î is the mapping w â†’ Î¾, Ë†lw  .
This is usually called the Walsh-Hadamard transform of Î¾. For a Boolean function f : IFn2 â†’ IF2 , the Fourier transform FÌ‚ = F(fË†) simply gives the correlation
between f and the linear functions: FÌ‚ (w) = c(f, lw ).
For Î¾, Î· âˆˆ Bn , their convolution Î¾ âŠ— Î· âˆˆ Bn is given by

Î¾(x + t)Î·(t) .
(Î¾ âŠ— Î·)(x) =
tâˆˆIFn
2

264

Johan WalleÌn

Clearly, Bn is a commutative, unital real algebra also under convolution as multiplication. The unity is the function Î´ such that Î´(0) = 1 and Î´(x) = 0 for
x = 0. As usual, the Fourier transform is an algebra isomorphism between the
commutative, unital real algebras Bn , +, Â· and Bn , +, âŠ—.
Let f : IFn2 â†’ IFm
2 be a Boolean function. Since the correlation of a linear
f
approximation of f is given by C(u â†
âˆ’ w) = F(l
u f )(w), the correlation of linear
approximations can conveniently
be
studied
using
the Fourier transform. Since

lu f can be expressed as i:ui =1 fi , where fi denotes the ith component of f , we
have the convolutional representation
f

C(u â†
âˆ’ w) =



FÌ‚i ,

i:ui =1

where FÌ‚i = F(fË†i ). Especially when using the convolutional representation, it
f

will be convenient to consider C(u â†
âˆ’ w) as a function of w with u ï¬xed.

3

Linear Approximations of Addition Modulo 2n

3.1

k-Independent Recurrences

We will take a slightly abstract approach to deriving algorithms for studying
linear approximations of addition modulo 2n , since this approach might turn
out to be useful also for some related mappings. The key to the algorithms are
a certain class of k-independent recurrences. The name comes from the fact that
they will be used to express the correlation of linear approximations of functions
whose ith output bit is independent of the (i + k)th input bit an higher.
We let ei âˆˆ IFn2 denote a vector whose ith component is 1 and the other 0.
If x âˆˆ IFn2 , x denotes the component-wise complement of x: xi = xi + 1. Let
eq : IFn2 Ã— IFn2 â†’ IFn2 be deï¬ned by eq(x, y)i = 1 if and only if xi = yi . That is,
eq(x, y) = x + y. For x, y âˆˆ IFn2 , we let xy = (xnâˆ’1 ynâˆ’1 , . . . , x1 y1 , x0 y0 )t denote
their component-wise product.
Deï¬nition 2. A function f : IFn2 Ã— IFn2 â†’ IR is k-independent, if f (x, y) = 0
whenever xj = 0 or yj = 0 for some j â‰¥ k. Let r0 , r : IFn2 Ã— IFn2 â†’ IR be kindependent functions. A recurrence Ri = Rir0 ,r is k-independent, if it has the
form
R0 (x, y) = r0 (x, y) , and

1  i+k
r(x , y) + r(x, y i+k ) + Ri (x, y) âˆ’ Ri (xi+k , y i+k
Ri+1 (x, y) =
2
for i > 0, where we for compactness have denoted z i+k = z + ei+k . Note that Rj
is a k + j-independent function for all j.
Note that k-independent recurrences can be eï¬ƒciently computed, provided that
we eï¬ƒciently can compute the base cases r and r0 . The crucial observation is

Linear Approximations of Addition Modulo 2n

265

that at most one of the terms in the expression for Ri+1 is non-zero, and that
we can determine which of the four terms might be non-zero by looking only
at xi+k and yi+k . The four terms consider the cases (xi+k , yi+k ) = (1, 0), (0, 1),
(0, 0), and (1, 1), respectively. This observation yields the following lemma.
Lemma 1. Let Ri = Rir0 ,r be a k-independent recurrence. Then
R0 (x, y) = r0 (x, y) , and

1
r(xei+k , yei+k ) ,
Ri+1 (x, y) = 21
xi+k
Ri (xei+k , yei+k ) ,
2 (âˆ’1)

if xi+k = yi+k and
if xi+k = yi+k .

It turns out that the k-independent recurrences of interest can be solved by
ï¬nding a certain type of common preï¬x of the arguments. Towards this end, we
deï¬ne the common preï¬x mask of a vector.
Deï¬nition 3. The common preï¬x mask cpmki : IFn2 â†’ IFn2 is for all j deï¬ned
by cpmki (x)j = 1 if and only if k â‰¤ j < k + i and x = 1 for all j <  < k + i.


Let wH (x) = {i | xi = 0} denote the Hamming weight of x âˆˆ IFn2 .
Lemma 2. Let Ri = Rir0 ,r be a k-independent recurrence. Denote r1 = r, and
let z = cpmki (eq(x, y)),  = wH (z) and s = (âˆ’1)wH (zxy) . Let b = 0, if xz = yz
and let b = 1 otherwise. Then
Ri (x, y) = s Â· 2 rb (xz, yz) .
Proof. For i = 0, cpmk0 (eq(x, y)) = 0,  = 0, s = 1, and b = 0. Thus, the
lemma holds for i = 0, so consider i + 1. Let x = xei+k , y  = yei+k , z  =
  
cpmki (eq(x , y  )),  = wH (z  ), s = (âˆ’1)wH (z x y ) , and b = 0, if x z  = y  z  and
b = 1 otherwise. By Lemma 1, there are two cases to consider. If xi+k = yi+k ,
z = ei+k ,  = 1, s = 1, and b = 1. In this case sÂ·2 rb (xz, yz) = 12 r(xei+k , yei+k ) =
Ri+1 (x, y). If xi+k = yi+k , z = ei+k +z  ,  =  +1, s = s (âˆ’1)xi+k , and b = b . In

this case, sÂ·2 rb (xz, yz) = 12 (âˆ’1)xi+k Â·s 2 rb (x z  , y  z  ) = 12 (âˆ’1)xi+k Ri (x , y  ) =
Ri+1 (x, y).


We will next consider the convolution of k-independent recurrences.
Lemma 3. Let Ri = RiÎ´,Î´ be a 0-independent recurrence, and let f : IFn2 â†’ IR be
k-independent. Deï¬ne Si = Ri+k âŠ— f , s = f , and s0 = Rk âŠ— f . Then Si = Sis0 ,s
is a k-independent recurrence.
Proof. Clearly, s0 and s are k-independent. Furthermore, S0 = Rk âŠ— f = s0
by deï¬nition. Finally, 2Si+1 (x, y) = 2R(i+k)+1 (x, y) âŠ— f (x, y) = (Î´(xi+k , y) +
Î´(x, y i+k ) + Ri+k (x, y) âˆ’ Ri+k (xi+k , y i+k )) âŠ— f (x, y) = f (xi+k , y) + f (x, y i+k ) +
(Ri+k âŠ— f )(x, y) âˆ’ (Ri+k âŠ— f )(xi+k , y i+k ), where we have used the notation
z i+k = z + ei+k .



266

3.2

Johan WalleÌn

Linear Approximations of the Carry Function

In this subsection, we derive a classiï¬cation of the linear approximations of the
carry function modulo 2n . It will turn out that the correlation of arbritrary
linear approximations of the carry function can be expressed as a recurrence of
the type studied in the previous subsection. We will identify the vectors in IFn2
and the elements in ZZ 2n using the natural correspondence
(xnâˆ’1 , . . . , x1 , x0 )t âˆˆ IFn2 â†” xnâˆ’1 2nâˆ’1 + Â· Â· Â· + x1 21 + x0 20 âˆˆ ZZ 2n .
To avoid confusion, we sometimes use âŠ• and  to denote addition in IFn2 and
ZZ 2n , respectively.
Deï¬nition 4. Let carry : IFn2 Ã— IFn2 â†’ IFn2 be the carry function for addition
modulo 2n deï¬ned by carry(x, y) = x âŠ• y âŠ• (x  y), and let ci = carryi denote
the ith component of the carry function for i = 0, . . . , n âˆ’ 1.
Note that the ith component of the carry function can be recursively computed
as c0 (x, y) = 0, and ci+1 (x, y) = 1 if and only if at least two of xi , yi and ci (x, y)
are 1. By considering the 8 possible values of xi , yi and ci (x, y), we see that
cÌ‚0 (x, y) = 1 and cÌ‚i+1 (x, y) = 12 (âˆ’1)xi + (âˆ’1)yi + cÌ‚i (x, y) âˆ’ (âˆ’1)xi +yi cÌ‚i (x, y) .
Thus we have
Lemma 4. The Fourier transform of the carry function cÌ‚i is given by the recurrence
CÌ‚0 (v, w) = Î´(v, w) , and

1
Î´(v + ei , w) + Î´(v, w + ei ) + CÌ‚i (v, w) âˆ’ CÌ‚i (v + ei , w + ei ) ,
CÌ‚i+1 (v, w) =
2
for i = 0, . . . , n âˆ’ 1.
Note that this indeed is a 0-independent recurrence.
In the sequel, we will need a convenient notation for stripping oï¬€ ones from
the high end of vectors.
Deï¬nition 5. Let x âˆˆ IFn2 and  âˆˆ {0, . . . , n}. Deï¬ne strip(x) to be the vector
in IFn2 that results when the highest component that is 1 in x (if any) is set to
0. By convention, strip(0) = 0. Similarly, let strip(, x) denote the vector that
results when all but the  lowest ones in x have been set to zero. For example,
strip(2, 1011101) = 0000101.
Let u âˆˆ IFn2 and let {i | ui = 1} = {k1 , . . . , km } with k < k+1 . Deï¬ne j0 = 0
and j+1 = k+1 âˆ’ k for  = 0, . . . , m âˆ’ 1. Then
carry

C(u â†âˆ’âˆ’âˆ’ v, w) =



CÌ‚i (v, w) =

i:ui =1

m

i=1

Deï¬ne a sequence of recurrences S0,i , . . . , Sm,i by
S0,i = Î´ , and
S+1,i = CÌ‚i+k âŠ— S,j ,

CÌ‚ki (v, w) .

Linear Approximations of Addition Modulo 2n

267

for  = 0, . . . , m âˆ’ 1. The crucial observation is that
carry

S,j (v, w) = C(strip(, u) â†âˆ’âˆ’âˆ’ v, w)
carry

for all . Thus, C(u â†âˆ’âˆ’âˆ’ v, w) = Sm,jm (v, w).
Lemma 5. Let S,i , j , and k be as above. Deï¬ne s , s by s1 = s1 = Î´, and for
s ,s

 > 0 by s+1 = S,j and s+1 = s . Then S,i = S,i  is a kâˆ’1 -independent
recurrence for all  > 0, where k0 = 0.
s ,s

Proof. For  = 1, the result is clear. If S,i = S,i  is a kâˆ’1 -independent
recurrence for some  â‰¥ 1, then S,j is a j +kâˆ’1 = k -independent function. By
f0 ,f
is a k -independent recurrence with f = S,j = s+1
Lemma 3, S+1,i = S+1,i
and f0 = CÌ‚k âŠ— S,j = CÌ‚k âŠ— (CÌ‚j +kâˆ’1 âŠ— Sâˆ’1,jâˆ’1 ) = CÌ‚k âŠ— CÌ‚k âŠ— Sâˆ’1,jâˆ’1 =
Sâˆ’1,jâˆ’1 = s+1 .


For any function f , we let f 0 denote the identity function and f i+1 = f â—¦ f i .
Lemmas 2 and 5 now give
Lemma 6. The correlation of any linear approximation of the carry function is
carry
given recursively as follows. First, C(0 â†âˆ’âˆ’âˆ’ v, w) = Î´(v, w). Second, if u = 0,
let j âˆˆ {0, . . . , n âˆ’ 1} be maximal such that uj = 1. If strip(u) = 0, let k be
maximal such that strip(u)k = 1. Otherwise, let k = 0. Denote i = j âˆ’ k. Let
z = cpmki (eq(v, w)),  = wH (z), and s = (âˆ’1)wH (zvw) . If vz = wz, set b = 2. Set
b = 1 otherwise. Then
carry

carry

C(u â†âˆ’âˆ’âˆ’ v, w) = s Â· 2âˆ’ C(stripb (u) â†âˆ’âˆ’âˆ’ vz, wz) .
Our next goal is to extract all the common preï¬x masks computed in the
previous lemma, and combine them into a single common preï¬x mask depending
on u. This gives a more convenient formulation of the previous lemma.
Deï¬nition 6. The common preï¬x mask cpm : IFn2 Ã— IFn2 â†’ IFn2 is deï¬ned recursively as follows. First, cpm(0, y) = 0. Second, if x = 0, let j be maximal such
that xj = 1. If strip(x) = 0, let k be maximal such that strip(x)k = 1. Otherwise,
let k = 0. Denote i = j âˆ’ k and z = cpmki (y) If zy = z, set b = 2. Set b = 1
otherwise. Then
cpm(x, y) = cpmki (y) + cpm(stripb (x), y) .
Theorem 1. Let u, v, w âˆˆ IFn2 , and let z = cpm(u, eq(v, w)). Then

0 ,
if vz = 0 or wz = 0, and
carry
C(u â†âˆ’âˆ’âˆ’ v, w) =
wH (vw)
âˆ’wH (z)
Â·2
, otherwise.
(âˆ’1)
Since the only nonlinear part of addition modulo 2n is the carry function, it
should be no surprise that the linear properties of addition completely reduce
to those of the carry function. Subtraction is also straightforward. When we are

âˆ’ v, w, we are actually approximating
approximating the relation xy = z by u â†

âˆ’ u, w. With this observation, it is trivial to prove
the relation z  y = x by v â†

268

Johan WalleÌn

Lemma 7. Let u, v, w âˆˆ IFn2 . The correlations of linear approximations of addition and subtraction modulo 2n are given by


carry



carry

âˆ’ v, w) = C(u â†âˆ’âˆ’âˆ’ v + u, w + u) , and
C(u â†
C(u â†
âˆ’ v, w) = C(v â†âˆ’âˆ’âˆ’ u + v, w + v) .
Moreover, the mappings (u, v, w) â†’ (u, v + u, w + u) and (u, v, w) â†’ (v, u +
v, w + v) are permutations in (IFn2 )3 .

4

The Common Preï¬x Mask

4.1

RAM Model

We will use a standard RAM model of computation consisting of n-bit memory
cells, logical and arithmetic operations, and conditional branches. Speciï¬cally,
we will use bitwise and (âˆ§), or (âˆ¨), exclusive or (âŠ•) and negation (Â·), logical
shifts ( and ), and addition and subtraction modulo 2n ( and ). As a
notational convenience, we will allow our algorithms to return values of the form
s2âˆ’k , where s âˆˆ {0, 1, âˆ’1}. In our RAM model, this can be handled by returning
s and k in two registers.
4.2

Computing cpm

To make the domain of cpm clear, we write cpmn = cpm : IFn2 Ã— IFn2 â†’ IFn2 . We
will extend the deï¬nition of cpm to a 3-parameter version.
Deï¬nition 7. Let cpmn : {0, 1} Ã— IFn2 Ã— IFn2 â†’ IFn2 be deï¬ned by cpmn (b, x, y) =
(znâˆ’1 , . . . , z0 )t , where z = cpmn+1 ((b, x)t , (0, y)t ).
Lemma 8 (Splitting lemma). Let n = k +  with k,  > 0. For any vector
x âˆˆ IFn2 , let xL âˆˆ IFk2 and xR âˆˆ IF2 be such that x = (xL , xR )t . Then
cpmn (x, y) = (cpmk (xL , y L ), cpm (b, xR , y R ))t ,
L
L L
where b = xL
0 if and only if (y0 , cpmk (x , y )0 ) = (1, 1).

Proof. Let w = wH (xL ) and z L = cpmk (xL , y L ). If w = 0, the result is trivial.
L
If w = 1 and xL
0 = 1, b = 1 and the result holds. If w = 1 and x0 = 0, b = 1
L
L
L
if and only if z0 = 1 and y0 = 1. If w = 2 and x0 = 1, b = 0 if and only if
z0L = 1 and y0L = 1. Finally, if w = 2 and xL
0 = 0, or w > 2, the result follows by
induction.


Using this lemma, we can easily come up with an Î˜(log n)-time algorithm
for computing cpmn (x, y). For simplicity, we assume that n is a power of two (if
not, the arguments can be padded with zeros). The basic idea is to compute both
cpmn (0, x, y) and cpmn (1, x, y) by splitting the arguments in halves, recursively
compute the masks for the halves in parallel in a bit-sliced manner, and then
combine the correct upper halves with the correct lower halves using the splitting
lemma. Applying this idea bottom-up gives the following algorithm.

Linear Approximations of Addition Modulo 2n

269

Theorem 2. Let n be a power of 2, let Î±(i) âˆˆ IFn2 consist of blocks of 2i ones
and zeros starting from the lest signiï¬cant end (e.g. Î±(1) = 0011 Â· Â· Â· 0011), and
let x, y âˆˆ IFn2 . The following algorithm computes cpm(x, y) using Î˜(log n) time
and constant space in addition to the Î˜(log n) space used for the constants Î±(i) .
1. Initialise Î² = 1010 Â· Â· Â· 1010, z0 = 0, and z1 = 1.
2. For i = 0, . . . , log2 n âˆ’ 1, do
(a) Let Î³b = ((y âˆ§ zb âˆ§ x) âˆ¨ (y âˆ§ zb âˆ§ x)) âˆ§ Î² for b âˆˆ {0, 1}.
(b) Set Î³b â† Î³b  (Î³b  2i ) for b âˆˆ {0, 1}.
(c) Let tb = (zb âˆ§ Î±(i) ) âˆ¨ (z0 âˆ§ Î³b âˆ§ Î±(i) ) âˆ¨ (z1 âˆ§ Î³b ) for b âˆˆ {0, 1}.
(d) Set zb â† tb for b âˆˆ {0, 1}.
(e) Set Î² â† (Î²  2i ) âˆ§ Î±(i+1) .
3. Return z0 .
Note that Î±(i) and the values of Î² used in the algorithm only depend on n. For
convenience, we introduce the following notation. Let Î² (i) âˆˆ IFn2 be such that
(i)
Î² = 1 iï¬€ âˆ’2i is a non-negative multiple of 2i+1 (e.g. Î² (1) = 0100 Â· Â· Â· 01000100).
For b âˆˆ {0, 1}, let
i

i

z (i) (b, x, y) = (cpm2i (b, x(n/2 âˆ’1) , y (n/2 âˆ’1) ), . . . , cpm2i (b, x(0) , y (0) ))t ,
i

i

where x = (x(n/2 âˆ’1) , . . . , x(0) )t and y = (y (n/2 âˆ’1) , . . . , y (0) )t . We also let x â†’
y, z denote the function â€œif x then y else zâ€. That is, x â†’ y, z = (x âˆ§ y) âˆ¨ (x âˆ§ z).
Proof (of Theorem 2). The algorithm clearly terminates in time Î˜(log n) and
uses constant space in addition to the masks Î±(i) . The initial value of Î² can also
be constructed in logarithmic time. We show by induction on i that Î² = Î² (i)
and zb = z (i) (b, x, y) at the start of the ith iteration of the for-loop. For i = 0,
this clearly holds, so let i â‰¥ 0. Consider the vectors x, y and zb split into
2i+1 -bit blocks, and let x , y  , and zb denote one of these blocks. After step 2a,
Î³b, = (y âˆ§ zb, ) â†’ x , x when  âˆ’ 2i is a multiple of 2i+1 , and Î³b, = 0
otherwise. Let Î¾ denote the bit of Î³b corresponding to the middle bit of the
block under consideration. By induction and the splitting lemma, cpm(b, x , y  ) =
L
L
R
R
(cpm(b, x , y  ), cpm(Î¾, x , y  ))t . After step 2b, a block of the form Ï‡00 Â· Â· Â· 0
in Î³b has been transformed to a block of the form 0Ï‡Ï‡ Â· Â· Â· Ï‡. In step 2c, the upper
half of each block zb is combined with the corresponding lower half of the block
zÎ¾ to give tb = cpm(b, x , y  ). That is, tb = z (i+1) (b, x, y). Finally, Î² = Î² (i+1)
after step 2e.


Since the Hamming weight can be computed in time O(log n), we have the
following corollary.


Corollary 1. Let u, v, w âˆˆ IFn2 . The correlation coeï¬ƒcients C(u â†
âˆ’ v, w) and


C(u â†
âˆ’ v, w) can be computed in time Î˜(log n) (using the algorithm in Theorem 2
and the expressions in Theorem 1 and Lemma 7).

270

5

Johan WalleÌn

Generating Approximations

In this section, we derive a recursive description of the linear approximations
carry
u â†âˆ’âˆ’âˆ’ v, w with a given non-zero correlation coeï¬ƒcient. For simplicity, we
only consider the absolute values of the correlation coeï¬ƒcients. The recursive
description immediately gives optimal generation algorithms for the linear apcarry
proximations. By Theorem 1, the magnitude of C(u â†âˆ’âˆ’âˆ’ v, w) is either zero or
1
a power of 2 . Thus, we start by considering the set of vectors (u, v, w) âˆˆ (IFn2 )3
carry
such that C(u â†âˆ’âˆ’âˆ’ v, w) = Â±2âˆ’k .
carry
We will use the splitting lemma to determine the approximations u â†âˆ’âˆ’âˆ’ v, w
with non-zero correlation and wH (cpmn (u, eq(v, w))) = k. Note that
cpmn (x, y) = (cpmnâˆ’1 (xL , y L ), cpm1 (b, x0 , y0 ))t ,
L
L L
where b = xL
0 iï¬€ (y0 , cpmnâˆ’1 (x , y )0 ) = (1, 1). Now, cpm1 (b, x0 , y0 ) = 1 iï¬€
L
b = 1 iï¬€ either x0 = 1 and (y0L , cpmnâˆ’1 (xL , y L )0 ) = (1, 1) or xL
0 = 0 and
(y0L , cpmnâˆ’1 (xL , y L )0 ) = (1, 1). Let the {0, 1}-valued bn (x, y) = 1 iï¬€ x0 = 1
and (y0 , cpmn (x, y)0 ) = (1, 1) or x0 = 0 and (y0 , cpmn (x, y)0 ) = (1, 1), let
âˆ’ v, w) = Â±2âˆ’k , bn (u, eq(v, w)) = 1}, and
F (n, k) = {(u, v, w) âˆˆ (IFn2 )3 | C(u â†
n 3
let G(n, k) = {(u, v, w) âˆˆ (IF2 ) | C(u â†
âˆ’ v, w) = Â±2âˆ’k , bn (u, eq(v, w)) = 0}.
Let A(n, k) = {(u, v, w) âˆˆ (IFn2 )3 | C(u â†
âˆ’ v, w) = Â±2âˆ’k }. Then A(n, k) is
formed from F (n âˆ’ 1, k âˆ’ 1) and G(n âˆ’ 1, k) by appending any three bits to
the approximations in F (n âˆ’ 1, k âˆ’ 1) (since u0 and eq(v, w)0 are arbitrary, and
cpmn (u, eq(v, w))0 = 1) and by appending {(0, 0, 0), (1, 0, 0)} to the approximations in G(n âˆ’ 1, k) (since u0 is arbitrary and cpmn (u, eq(v, w))0 = 0). Let S =
{(0, 0, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0)}, T = {(0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 1, 1)}, and
denote y = eq(v, w). We denote concatenation simply by juxtaposition.
The set F (n, k) can be divided into two cases.

1. The vectors with wH (cpmnâˆ’1 (uL , y L )) = k, bnâˆ’1 (uL , y L ) = 0, and bn (u, y) =
1. Since (u0 , y0 ) âˆˆ {(1, 0), (1, 1)} and cpmn (u, y)0 = 0, this set equals G(n âˆ’
1, k)(1, 0, 0).
2. The vectors with wH (cpmnâˆ’1 (uL , y L )) = k âˆ’ 1, bnâˆ’1 (uL , y L ) = 1 and
bn (x, y) = 1. Since (u0 , y0 ) âˆˆ {(0, 1), (1, 0)} and cpmn (u, y)0 = 1, this set
equals F (n âˆ’ 1, k âˆ’ 1)S.
That is,
F (n, k) = G(n âˆ’ 1, k)(1, 0, 0) âˆª F (n âˆ’ 1, k âˆ’ 1)S .
Clearly, F (1, 0) = {(1, 0, 0)} and F (n, k) = âˆ… when k < 0 or k â‰¥ n.
Similarly, G(n, k) can be divided into two cases:
1. The vectors with wH (cpmnâˆ’1 (uL , y L )) = k, bnâˆ’1 (uL , y L ) = 0, and bn (u, y) =
0. Since (u0 , y0 ) âˆˆ {(0, 0), (0, 1)} and cpmn (u, y)0 = 0, this set equals G(n âˆ’
1, k)(0, 0, 0).
2. The vectors with wH (cpmnâˆ’1 (uL , y L )) = k âˆ’ 1, bnâˆ’1 (uL , y L ) = 1 and
bn (u, y) = 0. Since (u0 , y0 ) âˆˆ {(0, 0), (1, 1)} and cpmn (u, y)0 = 1, this set
equals F (n âˆ’ 1, k âˆ’ 1)T .

Linear Approximations of Addition Modulo 2n

271

That is,
G(n, k) = G(n âˆ’ 1, k)(0, 0, 0) âˆª F (n âˆ’ 1, k âˆ’ 1)T .
Clearly, G(1, 0) = {(0, 0, 0)} and G(n, k) = âˆ… when k < 0 or k â‰¥ n.
Theorem 3. Let A(n, k) = {(u, v, w) âˆˆ (IFn2 )3 | C(u â†âˆ’âˆ’âˆ’ v, w) = Â±2âˆ’k }.
Then
carry

A(n, k) = F (n âˆ’ 1, k âˆ’ 1)(IF2 Ã— IF2 Ã— IF2 ) âˆª G(n âˆ’ 1, k){(0, 0, 0), (1, 0, 0)} ,
where F and G are as follows. Let S = {(0, 0, 0), (0, 1, 1), (1, 0, 1), (1, 1, 0)} and
T = {(0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 1, 1)}. First, F (1, 0) = {(1, 0, 0)}, G(1, 0) =
{(0, 0, 0)}, and F (n, k) = G(n, k) = âˆ… when k < 0 or k â‰¥ n. Second, when
0 â‰¤ k < n,
F (n, k) = G(n âˆ’ 1, k)(1, 0, 0) âˆª F (n âˆ’ 1, k âˆ’ 1)S , and
G(n, k) = G(n âˆ’ 1, k)(0, 0, 0) âˆª F (n âˆ’ 1, k âˆ’ 1)T .
Here, juxtaposition denotes concatenation.
From this theorem, it can be seen that there are 8(n âˆ’ 1) linear approximations
carry
u â†âˆ’âˆ’âˆ’ v, w with correlation Â± 12 . In the notation of formal languages, these are
the 8 approximations of the form
carry

0nâˆ’2 1a â†âˆ’âˆ’âˆ’ 0nâˆ’2 0b, 0nâˆ’2 0c
for arbritrary a, b, c âˆˆ {0, 1}, and the 8(n âˆ’ 2) approximations of the form
carry

0nâˆ’iâˆ’3 1d0i g â†âˆ’âˆ’âˆ’ 0nâˆ’iâˆ’3 0e0i 0, 0nâˆ’iâˆ’3 0f 0i 0
for (d, e, f ) âˆˆ {(0, 0, 1), (0, 1, 0), (1, 0, 0), (1, 1, 1)}, g âˆˆ {0, 1} and i âˆˆ {0, . . . , n âˆ’
3}.
The recursive description in Theorem 3 can easily be used to generate all
linear approximations with a given correlation. The straightforward algorithm
uses O(n) space and is linear-time in the number of generated approximations.
Clearly, this immediately generalise to the case where one or two of the selection
vectors are ï¬xed. By Lemma 7, this also generalise to addition and subtraction
modulo 2n .
Corollary 2. The set of linear approximations with correlation Â±2âˆ’k of the
carry function, addition, or subtraction modulo 2n can be generated in optimal
time (that is, linear in the size of the output) and O(n) space in the RAM
model (by straightforward application of the recurrence in Theorem 3 and the
expressions in Lemma 7). Moreover, one or two of the selection vectors can be
optionally ï¬xed.
Theorem 3 can also be used to determine the distribution of the correlation
coeï¬ƒcients.

272

Johan WalleÌn



Corollary 3. Let N (n, k) = {(u, v, w) âˆˆ (IFn2 )3 | C(u â†
âˆ’ v, w) = Â±2âˆ’k }. Then
N (n, k) = 22k+1

nâˆ’1
k

for all 0 â‰¤ k < n and N (n, k) = 0 otherwise. Thus, the number of linear
approximations with non-zero correlation is 2 Â· 5nâˆ’1 .
Proof. Based on Theorem 3, it is easy to see that
ï£±
ï£´
ï£²0 ,
N (n, k) = 2 ,
ï£´
ï£³
4N (n âˆ’ 1, k âˆ’ 1) + N (n âˆ’ 1, k) ,

if k < 0 or k â‰¥ n,
if n = 1 and k = 0, and
otherwise.

The claim clearly holds for n = 1. By induction, N (n, k) = 4N (n âˆ’ 1, k âˆ’
1) + N (n âˆ’ 1, k) = 4 Â· 22(kâˆ’1)+1 nâˆ’2
+ 22k+1 nâˆ’2
= 22k+1 nâˆ’1
k
k . Finally,
nâˆ’1 nâˆ’1 k kâˆ’1 nâˆ’1
nâˆ’1
.


k=0 N (n, k) = 2
k=0
k 4 =2Â·5
If we let X be a random variable with the distribution
Pr[X = k] = Pr [âˆ’ log2 |C(u â†
âˆ’ v, w)| = k | C(u â†
âˆ’ v, w) = 0] ,
u,v,w

we see that
Pr[X = k] =

nâˆ’1
k

4
5
k

k

1
5

nâˆ’1âˆ’k

nâˆ’1âˆ’k

4
1
for all 0 â‰¤ k < n, since 2 Â· 5nâˆ’1 nâˆ’1
= 22k+1 nâˆ’1
k
k . Thus, X is
5
5
4
4
binomially distributed with mean 5 (n âˆ’ 1) and variance 25
(n âˆ’ 1).

6

Conclusions

In this paper, we have considered improved algorithms for several combinatorial
problems related to linear approximations of addition modulo 2n . Our approach
might seem unnecessarily complicated considering the surprising simplicity of
the results (especially Theorem 3), but should lead to natural generalisations to
other recursively deï¬ned function. This generalisation and applications to block
ciphers are, however, left to later papers. A reference implementation of the
algorithms is available from the author.

Acknowledgements
This work was supported by the Finnish Defence Forces Research Institute of
Technology.

Linear Approximations of Addition Modulo 2n

273

References
1. Kazumaro Aoki, Kunio Kobayashi, and Shiho Moriai. Best diï¬€erential characteristic search for FEAL. In Fast Software Encryption 1997, volume 1267 of LNCS,
pages 41â€“53. Springer-Verlag, 1997.
2. Eli Biham and Adi Shamir. Diï¬€erential Cryptanalysis of the Data Encryption
Standard. Springer-Verlag, 1993.
3. Florent Chabaud and Serge Vaudenay. Links between diï¬€erential and linear cryptanalysis. In Advances in Cryptologyâ€“Eurocrypt 1994, volume 950 of LNCS, pages
356â€“365. Springer-Verlag, 1995.
4. Joan Daemen. Cipher and Hash Function Design: Methods Based on Linear and
Diï¬€erential Cryptanalysis. PhD thesis, Katholieke Universiteit Leuven, March
1995.
5. E.L. Lawler and D.E. Wood. Branch-and-bound methods: a survey. Operations
Research, 14(4):699â€“719, 1966.
6. Helger Lipmaa. On diï¬€erential properties of Pseudo-Hadamard transform and
related mappings. In Progress in Cryptologyâ€“Indocrypt 2002, volume 2551 of LNCS,
pages 48â€“61. Springer-Verlag, 2002.
7. Helger Lipmaa and Shiho Moriai. Eï¬ƒcient algorithms for computing diï¬€erential
properties of addition. In Fast Software Encryption 2001, volume 2355 of LNCS,
pages 336â€“350. Springer-Verlag, 2002.
8. Mitsuru Matsui. Linear cryptanalysis method for DES cipher. In Advances in
Cryptologyâ€“Eurocrypt 1993, volume 765 of LNCS, pages 386â€“397. Springer-Verlag,
1993.
9. Mitsuru Matsui. On correlation between the order of S-boxes and the strength
of DES. In Advances in Cryptologyâ€“Eurocrypt 1994, volume 950 of LNCS, pages
366â€“375. Springer-Verlag, 1995.
10. Mitsuru Matsui. New structure of block ciphers with provable security against
diï¬€erential and linear cryptanalysis. In Fast Software Encryption 1996, volume
1039 of LNCS, pages 205â€“218. Springer-Verlag, 1996.
11. Hiroshi Miyano. Addend dependency of diï¬€erential/linear probability of addition.
IEICE Trans. Fundamentals, E81-A(1):106â€“109, 1998.
12. Kaisa Nyberg. Linear approximations of block ciphers. In Advances in Cryptologyâ€“
Eurocrypt 1994, volume 950 of LNCS, pages 439â€“444. Springer-Verlag, 1995.
13. Serge Vaudenay. Provable security for block ciphers by decorrelation. In STACS
1998, volume 1373 of LNCS, pages 249â€“275. Springer-Verlag, 1998.

