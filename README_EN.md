# NeoAlzette Cryptanalysis Toolkit

English | [‰∏≠Êñá](README.md)

## Project Overview

This project implements a **high-performance cryptanalysis toolkit** for ARX ciphers (Addition, Rotation, XOR), with a particular focus on differential and linear cryptanalysis of the NeoAlzette 64-bit ARX-box. The project is based on cutting-edge research from CRYPTO 2022 and other top-tier conferences, providing a complete automated search and analysis framework.

> ‚ö†Ô∏è **Important Warning**: This is a **computationally intensive** research tool. Single searches may require hours to days of CPU time and several GB of memory. Please understand the algorithmic complexity before use.

### Core Algorithms

- **MEDCP (Maximum Expected Differential Characteristic Probability)**: Algorithm for maximum expected differential characteristic probability of modular addition/subtraction
- **MELCC (Maximum Expected Linear Characteristic Correlation)**: Algorithm for maximum expected linear characteristic correlation of modular addition/subtraction

### Algorithmic Significance

These algorithms solve the open problem posed by Niu et al. at CRYPTO 2022: **How to automatically search for differential-linear trails in ARX ciphers**. By transforming arbitrary matrix multiplication chains into Mixed Integer Quadratically-Constrained Programming (MIQCP), they achieve:

- Computational complexity reduction by approximately **8x**
- First implementation supporting **arbitrary output masks** for automatic search
- Discovery of **best differential-linear distinguishers** for SPECK, Alzette and other ARX ciphers

## Algorithm Background

### ARX Cipher Structure

ARX ciphers are based on three fundamental operations:
- **Addition (‚äû)**: Modular addition modulo 2^n
- **Rotation (<<<, >>>)**: Circular bit shifts
- **XOR (‚äï)**: Exclusive OR operation

This structure provides excellent performance in software implementations while maintaining sufficient cryptographic strength.

### Theoretical Foundation

This project is based on the following core theoretical achievements:

1. **Lipmaa-Moriai (2001)** - Efficient algorithms for computing differential properties of modular addition
2. **Wall√©n (2003)** - Correlation analysis of linear approximations for modular addition
3. **Mixed Integer Quadratically-Constrained Programming (MIQCP)** - For automatic search of differential-linear trails
4. **Highway Table Technology** - O(1) suffix lower bound queries with linear space complexity

### NeoAlzette Algorithm

NeoAlzette is an improved version based on the Alzette 64-bit ARX-box, featuring:

- **64-bit State**: (A, B) ‚àà F‚ÇÉ‚ÇÇ¬≤
- **Two-Subround Structure**: Each round contains two subround operations  
- **Nonlinear Functions**: F(A) = B = B ‚äû (A<<< 31) ‚äï (A <<< 17) ‚äï RC[0], F(B) = A = A ‚äû (B<<< 31) ‚äï (B <<< 17) ‚äï RC[5]
- **Linear Diffusion Layer**: L‚ÇÅ, L‚ÇÇ provide branch number guarantees
- **Round Constant Injection**: 16 predefined round constants

## Complete Project Structure

```
‚îú‚îÄ‚îÄ include/                          # Core algorithm header library
‚îÇ   ‚îú‚îÄ‚îÄ neoalzette.hpp               # NeoAlzette ARX-box core implementation
‚îÇ   ‚îú‚îÄ‚îÄ lm_fast.hpp                  # Lipmaa-Moriai differential fast enumeration
‚îÇ   ‚îú‚îÄ‚îÄ lm_wallen.hpp                # LM-Wall√©n hybrid model (differential+linear)
‚îÇ   ‚îú‚îÄ‚îÄ wallen_fast.hpp              # Wall√©n linear correlation fast computation
‚îÇ   ‚îú‚îÄ‚îÄ wallen_optimized.hpp         # Wall√©n optimized: precomputed automaton
‚îÇ   ‚îú‚îÄ‚îÄ highway_table.hpp            # Differential Highway suffix lower bound table
‚îÇ   ‚îú‚îÄ‚îÄ highway_table_lin.hpp        # Linear Highway suffix lower bound table
‚îÇ   ‚îú‚îÄ‚îÄ lb_round_full.hpp            # Complete round function differential bounds
‚îÇ   ‚îú‚îÄ‚îÄ lb_round_lin.hpp             # Complete round function linear bounds
‚îÇ   ‚îú‚îÄ‚îÄ suffix_lb.hpp                # Multi-round suffix differential bounds
‚îÇ   ‚îú‚îÄ‚îÄ suffix_lb_lin.hpp            # Multi-round suffix linear bounds
‚îÇ   ‚îú‚îÄ‚îÄ threshold_search.hpp         # Matsui threshold search framework
‚îÇ   ‚îú‚îÄ‚îÄ threshold_search_optimized.hpp # Parallelized threshold search
‚îÇ   ‚îú‚îÄ‚îÄ matsui_complete.hpp          # Complete Matsui Algorithm 2 implementation
‚îÇ   ‚îú‚îÄ‚îÄ canonicalize.hpp             # State canonicalization (rotation equivalence)
‚îÇ   ‚îú‚îÄ‚îÄ state_optimized.hpp          # Optimized state representation and caching
‚îÇ   ‚îú‚îÄ‚îÄ diff_add_const.hpp           # Modular addition by constant differential properties
‚îÇ   ‚îú‚îÄ‚îÄ mask_backtranspose.hpp       # Linear mask backward propagation
‚îÇ   ‚îú‚îÄ‚îÄ neoalz_lin.hpp               # NeoAlzette linear layer exact implementation
‚îÇ   ‚îú‚îÄ‚îÄ pddt.hpp                     # Partial Differential Distribution Table
‚îÇ   ‚îú‚îÄ‚îÄ pddt_optimized.hpp           # Optimized pDDT construction algorithms
‚îÇ   ‚îî‚îÄ‚îÄ trail_export.hpp             # Trail export and CSV formatting
‚îú‚îÄ‚îÄ src/                             # Main analysis tools
‚îÇ   ‚îú‚îÄ‚îÄ analyze_medcp.cpp            # üî• MEDCP trail searcher (main tool)
‚îÇ   ‚îú‚îÄ‚îÄ analyze_medcp_optimized.cpp  # ‚ö° Optimized MEDCP analyzer (recommended)
‚îÇ   ‚îú‚îÄ‚îÄ analyze_melcc.cpp            # üî• MELCC trail searcher (main tool)
‚îÇ   ‚îú‚îÄ‚îÄ analyze_melcc_optimized.cpp  # ‚ö° Optimized MELCC analyzer (recommended)
‚îÇ   ‚îú‚îÄ‚îÄ complete_matsui_demo.cpp     # Complete Matsui Algorithm 1&2 demonstration
‚îÇ   ‚îú‚îÄ‚îÄ bnb.cpp                      # Branch-and-bound search implementation
‚îÇ   ‚îú‚îÄ‚îÄ neoalzette.cpp               # NeoAlzette algorithm implementation
‚îÇ   ‚îú‚îÄ‚îÄ pddt.cpp                     # Partial Differential Distribution Table implementation
‚îÇ   ‚îú‚îÄ‚îÄ gen_round_lb_table.cpp       # Round lower bound table generator
‚îÇ   ‚îú‚îÄ‚îÄ highway_table_build.cpp      # Differential Highway table builder
‚îÇ   ‚îú‚îÄ‚îÄ highway_table_build_lin.cpp  # Linear Highway table builder
‚îÇ   ‚îú‚îÄ‚îÄ threshold_lin.cpp            # Linear threshold search
‚îÇ   ‚îú‚îÄ‚îÄ search_beam_diff.cpp         # Beam search differential analysis
‚îÇ   ‚îî‚îÄ‚îÄ milp_diff.cpp                # MILP differential model (experimental)
‚îú‚îÄ‚îÄ papers/                          # Core theoretical papers (PDF)
‚îú‚îÄ‚îÄ papers_txt/                      # Text-extracted versions of papers
‚îú‚îÄ‚îÄ PAPERS_COMPLETE_ANALYSIS_CN.md   # üî• Complete analysis of 11 papers (25,000+ words)
‚îú‚îÄ‚îÄ ALZETTE_VS_NEOALZETTE.md         # Alzette vs NeoAlzette design comparison
‚îú‚îÄ‚îÄ ALGORITHM_IMPLEMENTATION_STATUS.md # Paper algorithm implementation status
‚îú‚îÄ‚îÄ CMakeLists.txt                   # Build configuration file
‚îú‚îÄ‚îÄ LICENSE                          # GPL v3.0 open source license
‚îî‚îÄ‚îÄ .gitignore                       # Git ignore configuration
```

### Core File Descriptions

#### üî• Main Analysis Tools
- **`analyze_medcp.cpp`** - **MEDCP Differential Analyzer**: Search for optimal differential trails with Highway acceleration, CSV export, weight histograms
- **`analyze_melcc.cpp`** - **MELCC Linear Analyzer**: Search for optimal linear trails with exact backward propagation, beam search

#### üßÆ Core Algorithm Implementations
- **`lm_fast.hpp`** - **Lipmaa-Moriai 2001 Algorithm**: O(log n) time modular addition differential probability computation with prefix pruning
- **`wallen_fast.hpp`** - **Wall√©n 2003 Algorithm**: O(log n) time modular addition linear correlation computation  
- **`highway_table*.hpp`** - **Highway Table Technology**: Precomputed suffix bounds, O(1) query time, linear space

#### üîß Auxiliary Tools
- **`highway_table_build*.cpp`** - Highway table precomputation tools (optional, for large-scale search acceleration)
- **`gen_round_lb_table.cpp`** - Round lower bound table generator (optimize single-round pruning)
- **`trail_export.hpp`** - Unified CSV export format (for subsequent analysis)

#### üìö Core Documentation
- **`PAPERS_COMPLETE_ANALYSIS_CN.md`** - **üî• Complete analysis guide for 11 papers**
  - 25,000+ words of deep technical analysis
  - Complete chain from mathematical formulas to code implementation
  - Engineering art analysis of Alzette's three-step pipeline design
  - Layer-by-layer analysis of Lipmaa-Moriai, Wall√©n and other core algorithms
  - Clarification of common confusions and learning path guidance
  - **Essential reading when encountering algorithm understanding difficulties**

## Build Instructions

### System Requirements

- **Compiler**: Modern C++20 compiler (GCC 10+ / Clang 12+ / MSVC 2019+)
- **Memory**: Recommended 8GB+ RAM (for large search tasks)
- **CPU**: x86_64 processor with popcount instruction support

### Build Steps

```bash
# Clone repository
git clone <repository-url>
cd neoalzette_search

# Create build directory
mkdir build && cd build

# Configure build
cmake ..

# Compile
make -j$(nproc)

# Optional: Build demo programs
cmake -DNA_BUILD_DEMOS=ON ..
make -j$(nproc)
```

### Build Artifacts

#### üî• Main Analysis Tools
- **`analyze_medcp`** - Standard MEDCP trail search
- **`analyze_medcp_optimized`** - **‚ö° Optimized MEDCP Analyzer** (Recommended)
- **`analyze_melcc`** - Standard MELCC trail search  
- **`analyze_melcc_optimized`** - **‚ö° Optimized MELCC Analyzer** (Recommended)

#### üîß Auxiliary Tools
- **`complete_matsui_demo`** - Complete Matsui Algorithm 1&2 demonstration
- `highway_table_build*` - Highway table construction tools

#### ‚ö° Optimized Version Features
**New optimized versions include the following improvements**:
- **Wall√©n Algorithm Rewrite**: Precomputed automaton replaces runtime recursion, 2-5x performance improvement
- **Parallelized Search**: Multi-threaded work-stealing to fully utilize multi-core CPUs
- **Cache-Friendly Design**: 64-bit packed state representation reduces memory access overhead
- **Fast Canonicalization**: Optimized bit manipulation algorithms accelerate state equivalence checking  
- **Improved Pruning Strategy**: Better lower bound estimation and duplicate state detection

## Usage

### ‚ö†Ô∏è Essential Pre-requisites

These tools are **computationally intensive** research-grade algorithm implementations:

- **Time Complexity**: Exponential worst-case, actual performance depends on pruning efficiency
- **Space Complexity**: O(2^{weight_cap}) memory usage
- **Recommended Environment**: High-performance servers or clusters, not personal laptops
- **Parameter Tuning**: Start with small parameters, gradually increase complexity

### MEDCP Trail Search

MEDCP analyzer uses **Matsui threshold search + Lipmaa-Moriai local enumeration**, supporting complete trail path recording.

#### Basic Syntax
```bash
./analyze_medcp R Wcap [highway.bin] [options]
```

#### Parameter Description
- **`R`** - Number of search rounds (recommended range: 4-12 rounds)
- **`Wcap`** - Global weight cap (lower is faster, recommend 20-50)
- **`highway.bin`** - Optional precomputed Highway table file

#### Detailed Options
- **`--start-hex dA dB`** - Starting differential state (32-bit hexadecimal)
  - `dA`: A register difference
  - `dB`: B register difference
  - Example: `--start-hex 0x80000000 0x1`
- **`--k1 K`** - Top-K candidates for var-var addition (default 4, range 1-16)
- **`--k2 K`** - Top-K candidates for var-const addition (default 4, range 1-16)
- **`--export path.csv`** - Export search summary to CSV file
- **`--export-trace path.csv`** - Export complete optimal trail path
- **`--export-hist path.csv`** - Export weight distribution histogram
- **`--export-topN N path.csv`** - Export top-N best results

#### Standard Version Examples
```bash
# Beginner example: 6-round search, weight cap 25 (~1 minute)
./analyze_medcp 6 25

# Standard search: 8 rounds, weight 35, custom starting difference
./analyze_medcp 8 35 --start-hex 0x1 0x0
```

#### ‚ö° Optimized Version Examples (Recommended)
```bash
# Basic optimized search: auto-detect thread count
./analyze_medcp_optimized 6 25

# High-performance search: specify thread count, use Highway table
./analyze_medcp_optimized 8 35 highway_diff.bin --threads 8 --k1 8 --k2 8

# Fast search: use fast canonicalization (suitable for large-scale search)
./analyze_medcp_optimized 10 40 --fast-canonical --threads 16

# Complete optimized analysis: export detailed results
./analyze_medcp_optimized 8 30 \
  --export-trace trail_opt.csv \
  --export-hist histogram_opt.csv \
  --export-topN 10 top10_opt.csv \
  --threads 8

# Performance comparison test
echo "Standard version:" && time ./analyze_medcp 6 25
echo "Optimized version:" && time ./analyze_medcp_optimized 6 25 --threads 4
```

#### Performance Improvement Description
- **2-5x Speed Improvement**: Optimized Wall√©n algorithm and parallelization
- **Lower Memory Usage**: Packed state representation and memory pool management
- **Better Scalability**: Multi-threading support fully utilizes modern multi-core CPUs

### MELCC Trail Search

MELCC analyzer uses **priority queue search + Wall√©n linear enumeration**, supporting precise backward mask propagation.

#### Basic Syntax
```bash
./analyze_melcc R Wcap [options]
```

#### Parameter Description
- **`R`** - Number of search rounds (recommended range: 4-10 rounds)
- **`Wcap`** - Weight cap (linear analysis typically more restrictive than differential)

#### Detailed Options
- **`--start-hex mA mB`** - Starting linear masks (32-bit hexadecimal)
  - `mA`: A register mask
  - `mB`: B register mask
- **`--lin-highway H.bin`** - Linear Highway table file
- **`--export path.csv`** - Export analysis summary
- **`--export-trace path.csv`** - Export optimal trail
- **`--export-hist path.csv`** - Export weight distribution
- **`--export-topN N path.csv`** - Export top-N results

#### Standard Version Examples
```bash
# Beginner example: 6-round linear search
./analyze_melcc 6 20

# High-weight mask search
./analyze_melcc 8 25 --start-hex 0x80000001 0x0
```

#### ‚ö° Optimized Version Examples (Recommended)
```bash
# Basic optimized linear search
./analyze_melcc_optimized 6 20

# High-performance linear analysis: multi-threading + Highway table
./analyze_melcc_optimized 8 25 --lin-highway highway_lin.bin --threads 6

# Fast linear search: use fast canonicalization
./analyze_melcc_optimized 10 30 --fast-canonical --threads 8

# Complete optimized linear analysis pipeline
./analyze_melcc_optimized 8 25 \
  --start-hex 0x1 0x0 \
  --export-trace linear_trail_opt.csv \
  --export-topN 5 best_linear_opt.csv \
  --threads 6

# Performance comparison: standard vs optimized
time ./analyze_melcc 6 20
time ./analyze_melcc_optimized 6 20 --threads 4
```

#### Linear Analysis Specific Optimizations
- **Precomputed Wall√©n Automaton**: Avoids runtime recursion, significantly improves enumeration speed
- **Optimized Backward Propagation**: Precise (L^{-1})^T computation reduces unnecessary state generation
- **Improved Priority Queue**: Uses packed states to reduce memory footprint and improve cache hit rates

### Highway Table Construction

```bash
# Build differential Highway table (optional, for search acceleration)
./highway_table_build output_diff.bin [max_rounds]

# Build linear Highway table
./highway_table_build_lin output_lin.bin [max_rounds]
```

### Paper Algorithm Demonstration

```bash
# Demonstrate complete Matsui Algorithm 1&2 implementation
./complete_matsui_demo --full

# Quick algorithm correctness verification
./complete_matsui_demo --quick
```

### Advanced Options

#### Export and Analysis Options

```bash
# Export complete trail paths
./analyze_medcp 8 30 --export-trace trail.csv

# Export weight distribution histogram
./analyze_medcp 8 30 --export-hist histogram.csv

# Export top-N best results
./analyze_medcp 8 30 --export-topN 10 top10.csv
```

#### Search Parameter Tuning

- `--k1 K`: Top-K candidates for var-var addition (default 4)
- `--k2 K`: Top-K candidates for var-const addition (default 4)
- Increasing K values may find better trails but significantly increases search time

### Parallelization and Cluster Deployment

This toolkit is designed as a **CPU-intensive** application, supporting:

- **Multi-core Parallelism**: Use `make -j$(nproc)` to fully utilize multi-core CPUs
- **Memory Efficiency**: Uses memoization and incremental computation to reduce memory usage
- **Cluster-Friendly**: Tools run independently, easy to deploy in cluster environments

#### Cluster Usage Recommendations

```bash
# Split large tasks into multiple subtasks for parallel execution
for r in {6..12}; do
    for w in {20..40..5}; do
        sbatch run_analysis.sh $r $w
    done  
done
```

## Performance Characteristics & Computational Complexity

### Algorithm Complexity Analysis

#### Core Algorithm Complexities
- **Lipmaa-Moriai Enumeration**: Average << 2^n (highly efficient prefix infeasibility pruning)
- **Wall√©n Linear Computation**: O(log n) time with incremental popcount optimization
- **Highway Table Queries**: O(1) time, O(4^rounds) space precomputation
- **Threshold Search**: O(state_space √ó branching_factor^rounds), actual depends on pruning efficiency

#### Practical Performance Estimation
```
Search space size ‚âà (valid differences) √ó (rounds) √ó (branching factor)
Where:
- Valid differences ‚âà 2^{32} √ó pruning_rate (typically < 1%)
- Branching factor ‚âà average successors per state (50-500)
- Pruning efficiency ‚âà lower bound pruning hit rate (90%+)
```

### Detailed Resource Consumption Table

| Configuration | Rounds | Weight Cap | Memory Usage | CPU Time | Disk I/O | Use Case |
|---------------|--------|------------|--------------|----------|----------|-----------|
| **Entry Level** | 4-6 | 15-25 | 100MB-500MB | 30sec-5min | Minimal | Algorithm validation, teaching demos |
| **Standard** | 6-8 | 25-35 | 500MB-2GB | 5min-2hr | Medium | Paper experiments, method comparison |
| **Professional** | 8-10 | 35-45 | 2GB-8GB | 2hr-1day | High | Deep analysis, optimal trails |
| **Research** | 10-12+ | 45+ | 8GB-32GB | 1day-1week | Extreme | Breakthrough research, cluster computing |

### Memory Usage Pattern

```
Memory component analysis
Memoization hash table: O(search states) ‚âà 10MB - 1GB
Priority queue:         O(active nodes) ‚âà 1MB - 100MB
Highway tables:         O(4^max_rounds) ‚âà 16MB - 4GB
Trail path storage:     O(max_rounds √ó Top-N) ‚âà 1MB - 10MB
Temporary comp cache:   O(single round expansion) ‚âà 10MB - 100MB
```

### Personal Computer Usage Recommendations

#### **4-Round Search - Completely Feasible**
- ‚è±Ô∏è **Time**: 10 seconds to 10 minutes (depending on weight cap)
- üíæ **Memory**: 50MB to 1GB (typically <500MB)
- üíª **CPU**: Moderate usage, won't freeze computer
- üìÅ **Storage**: Almost no disk I/O required

#### Recommended Testing Process
```bash
# Step 1: Minimal test (guaranteed to succeed)
time ./analyze_medcp_optimized 4 15

# Step 2: Standard test  
time ./analyze_medcp_optimized 4 20 --threads 2

# Step 3: Challenge test (if hardware allows)
time ./analyze_medcp_optimized 4 25 --threads 4
```

## Development and Extension

### Adding New Cipher Algorithms

1. Define algorithm structures in `include/`
2. Implement round functions and state transitions
3. Adapt differential/linear local models
4. Add corresponding analysis programs

### Custom Search Strategies

```cpp
// Implement custom lower bound function
auto custom_lower_bound = [](const State& s, int round) -> int {
    // Custom bound calculation logic
    return compute_bound(s, round);
};

// Use custom strategy for search
auto result = matsui_threshold_search(rounds, start, cap, 
                                     next_states, custom_lower_bound);
```

## License

This project is licensed under the GNU General Public License v3.0. See [LICENSE](LICENSE) for details.

## üìö Learning Resource Guide

### **Documentation Usage Recommendations**
- **Want to get started quickly?** ‚Üí Read the "Usage" section of this README
- **Encountering algorithm confusion?** ‚Üí Refer to `PAPERS_COMPLETE_ANALYSIS_CN.md`
- **Need deep understanding?** ‚Üí Start with MnT operator, understand algorithm encapsulation layers
- **Optimization bottlenecks?** ‚Üí Consult "Performance Optimization" sections in paper analysis

### **Recommended Learning Path** 
```
Step 1: Familiarize with tools ‚Üí Run 4-round small tests, understand basic concepts
Step 2: Understand algorithms ‚Üí Read paper analysis, master mathematical principles
Step 3: Deep application ‚Üí Try 8-round analysis, explore parameter optimization  
Step 4: Advanced research ‚Üí Extend to other ARX ciphers, publish results
```

## Citation

If you use this toolkit in your research, please cite the relevant papers:

```bibtex
@inproceedings{miqcp2022,
  title={A MIQCP-Based Automatic Search Algorithm for Differential-Linear Trails of ARX Ciphers},
  author={Guangqiu Lv and Chenhui Jin and Ting Cui},
  booktitle={Cryptology ePrint Archive},
  year={2022}
}

@inproceedings{alzette2020,
  title={Alzette: A 64-Bit ARX-box},
  author={Christof Beierle and Alex Biryukov and Luan Cardoso dos Santos and others},
  booktitle={Annual International Cryptology Conference},
  pages={419--448},
  year={2020}
}
```

## Contributing

Issues and Pull Requests are welcome! Please ensure:

1. Code conforms to C++20 standards
2. Add appropriate tests and documentation
3. Follow existing code style
4. Provide detailed descriptions of changes

## Contact

For technical questions or collaboration inquiries, please contact through:

- Create GitHub Issues
- Email project maintainers
- Participate in relevant academic conferences and discussions

---

**Note**: This toolkit is intended for academic research and educational purposes only. Please do not use for malicious attacks or illegal activities.